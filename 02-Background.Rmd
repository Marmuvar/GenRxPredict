# Background  
\pagenumbering{arabic}
The United States pharmaceutical industry provided almost 194 billion daily doses of pharmaceuticals in 2021, representing around \$776 billion in wholesale costs and \$80 billion in patient out-of-pocket costs [@i22].  Considering the US population of around 332 million people, the wholesale cost, which is shared among insurers and patients, works out to around $2300 per person, while the out-of-pocket costs are around \$241 per person.  However, new drugs may provide a 3 to 6\% reduction in years of life lost from multiple disease states, providing a significant benefit to society in the years following their introduction [@l19].

In the United States, pharmaceutical products enter commercial trade after the Food and Drug Administration (FDA) issues a marketing authorization based on either a new drug application (NDA) for a novel "brand‚Äù drug product or an abbreviated new drug application (ANDA) for a generic drug product [@dpr84].  A separate pathway exists for complex molecules submitted under a biological licensing application, which is outside the scope of this paper.  An NDA documents extensive studies of product safety and efficacy and can represent over a billion dollars of development costs and over a decade of research expenditures [@sh22]. Branded pharmaceutical products are developed based on medical need, prevalence of disease and technical feasibility [@te09].  Therefore, branded product manufacturers have a luxury of time to optimize both the manufacturing process and selection of inactive ingredients that comprise the drug delivery system and individual dosage forms. Refinement occurs during preclinical trials and during the numerous production cycles required to produced clinical supplies and demonstrate the commercial manufacturing process [@bbc20].  

In contrast, a generic sponsor of an ANDA does not need to prove safety and efficacy through clinical trials.  Instead, they primarily need to demonstrate equivalent performance to the reference drug. Sponsors prove therapeutic equivalency between generic and branded products through a small clinical study in volunteers showing that there are no differences in the rate or amount of drug absorbed into the body.  Further, the brand and generic must be pharmaceutically equivalent, having the same active pharmaceutical ingredient, same dosage form, same strengths, and same route of administration [@cder17]. Since clinical effectiveness is a function of drug concentration, demonstration of similar drug concentrations makes it unnecessary for generic products to duplicate extensive clinical performance trials required for branded product approval [@mm09].  

Generic sponsors consider profit potential, dosage form complexity, and toxic material handling requirements as potential constraints in new product manufacture [@lcrs16]. Because generics require fewer clinical trials and less time to develop, the products may reflect the distinct formulation and manufacturing paradigms available at each company. Attempts to circumvent patents may result in differences between brand and generic formulations.  While the resultant generic product demonstrates clinical similarity to the branded product, it may have differences in the manufacturing process or inactive ingredients.  However, the cost of 5 years of generic drug development was projected to be around $2.5 million dollars, or around 1/400th the cost of the branded pharmaceutical [slb21].  

Reduced spending on pharmaceutical development provides meaningful value to the consumer.  While average cost in 2021 for brand pharmaceutical prescriptions were around \$21 for commercially insured individuals, the generic cost was around \$5, representing a four-fold savings. The combined role of insurance and low cost generic pharmaceutical prices is significant, considering the average out-of-pocket cost for a brand product was around \$91 without insurance [@i22].   

Given the scale of pharmaceutical investment, achieving meaningful investment returns is a necessary business objective.  Across all pharmaceutical companies, over $83 billion was spent on research and development in 2019, which was around a quarter of corporate costs [@cbo21].  These rates are justifiable, as up to 90\% of drug molecules are reported to fail in clinical studies [@sh22].  As a result, the internal return on investment for a cohort of large biopharmaceutical companies was observed to be only 3 to 7\% in a longitudinal review conducted by the Deloitte Centre for Health Solutions @dc21.  

To protect the development investment, brand pharmaceutical companies patent their novel discoveries.  In exchange for teaching the public details of the invention, the company receives a 20 year exclusive right to practice the invention [@usc13]. Further, the receipt of additional patents at a later date covering new applications may extend the exclusivity an additional 10 to 20 years due to overlapping terms.  Because generic medicines need to mimic the physiological performance and often compositions of the brand product, patents exposed generic products to infringement liability for producing clinical trial materials during development.  This is evident in the 1984 case of Roche Products, Inc. vs. Bolar Pharmaceutical Corp, in which federal court found Bolar had infringed on Roche's patents when producing non-commercial materials for preliminary a bioequivalence study [@rj14].  Although a regulatory pathway existed to approve generic drugs, the legal risks discouraged companies from pursuing generic products.  

In 1984, Congress approved into law the Drug Price Competition and Patent Term Restoration Act @dpr84, which established the modern approval pathways.  The act established a compromise between protecting intellectual property and enabling a development pathway for generic medicines.  Innovative products received additional years of patent protection based on the length of FDA application review that occurred concurrently with the patent.  Generic companies gained protection from infringement liability during developmental clinical studies conducted to support product an ANDA.  However, upon submitting an application, the generic sponsor had to attest to the absence of patents, expiry of all patents, an intent to withhold marketing until after patent expiry, or that any existing patents were invalid or not infringed upon.  

Under the new law, the act of submitting a drug product with an invalidity or infringement assertion became a surrogate act of infringement.  If the generic company made this claim, the branded company could file an infringement lawsuit within 45 days of the FDA's receipt of the application.  At that point, the law enjoined the FDA from approving the application until the earlier of 30 months or the resolution of any litigation.  If the generic company prevailed in litigation and were the first company to file an abbreviated drug application, they would themselves receive a 6 month exclusivity period to market the generic product before approval of any additional generics could be approved.  
 
Patents allow brand sponsors to sell a new drug at inflated prices due to a monopoly position [@crs21], and significant time is granted to defend the validity of product patents.   However, significant profit erosion occurs once generic products enter the market after the expiry of patents or exclusivity [@ow13], [@rw05].  The selling price for the first generic product was observed to be a median of around 76\% of the brand product.  Meanwhile, the selling price of the next four competitors each decreased the price around 20\%.  As a result, products with 5 or more generic products competed for a sales price observed to be around 95\% of the brand's wholesale product cost [@cl19].  

Considering litigation risks and effect of competition to decrease price, generic products have the best opportunity for profitability and highest legal risk before patents expire and other generics enter the market.  A lesser opportunity for profit and lower risk occurs when a generic can reach the market after all regulatory exclusivity periods expire but before other companies have eroded the sale price.  The period between first and last patent expiry presents an interesting opportunity for product introduction, as the risk of litigation may mitigate the benefits of entering the market before other competitors.  However, other competitors may be dissuaded from entering the market due to these risks, resulting in a higher market share.  

Because of the time required for product development and regulatory review, identification of development projects requires accurate forecasting of the competitive landscape three to six years after project inception. Equally, predicting competition during patent lifespans may lend critical insight in timing the starting points for new development projects.  Therefore, a significant benefit for improving predictions exists in performing data analysis on historical patterns in pharmaceutical product approvals, patent protection, and regulatory exclusivity.  

Other researchers have reported factors influencing generic competition.  Between 2012 and 2017, decreasing rates of generic product substitution in new markets were influenced by authorized generics, market revenue, and first-to-file status [@rlgk21].  Separately, generic companies may introduce a product at risk of adverse court decisions during unresolved litigation [@dhmn21].  When companies entered markets at risk, drug substance and drug product patents were significantly absent.  While the number of patents was not significantly associated with this decision, market sales below $50 million were a significant feature where companies entered at risk.  Market competition levels, market size, and dosage form were used to predict the presence or absence of drug shortages in a separate study [@dpfbk18].  Low priced drugs were observed to have a higher risk of shortages between 2008 and 2014.  While this study considered a binary classification, @bdk18 evaluated drug substance patents, patent term restoration, pediatric exclusivity periods, and statutory limitations of product approvals as variables predicting the fiscal quarter of product entry following brand product approval.  In a cohort of top selling drugs between 2000 and 2014, products having only secondary patents unrelated to the drug substance were observed to have earlier competition than products with a drug substance patent.   

From the prior studies, details about the brand product's patents and dosage forms could be used to in predictive models.  Because patents protect brand monopolies, the number and subject of said patents may estimate the magnitude of obstacles forestalling generic approvals.  Details available in the product labeling may also support predictions.  Dosage forms and ingredients used in the brand product may reflect underlying complexity that makes a product more difficult to copy.  This may be a function of either patented compositions or complexities of the dosage form itself.  Required packaging designs may reflect unique handling requirements that are difficult for generic companies to mimic.  

Evaluation of the FDA's published records of drug product approvals, patents, and labeling information will enable a comprehensive review of public details across a broad time range.  This will supplement previous studies, which relied on subsamples limited by contemporaneous products and market size.  Last, building a classification model for the presence or absence of competition will establish a screening tool for determining potential markets with first-to-file opportunity for generic companies without regard to specific timing of entry.  

```{r training_partitions, include = FALSE}
#per discussion here:
# https://stackoverflow.com/questions/15068981/removal-of-constant-columns-in-r
# accessed 9/15/2022
#eliminate ingredients with zero variance
chk_zero_var <- function(v) {
  if(any(is.na(v))) return(TRUE)
  if(is.numeric(v)){
    return(var(v, na.rm = TRUE) == 0)
  }
  else{
      return(FALSE)
  }
}

filter_zero_var <- function(tib) {
  to_drop <- sapply(tib, chk_zero_var)
  return(tib[!to_drop])
}

range_scale <- function(x){
  # Since this is called on test set, need to allow cases where min and max
  # are identical.  
  if (all(is.na(x))) return(x*0)
  if ((min(x) == 0) & (max(x) == 0))
      return(x*0)
  else
    return(x)
}

add_top_names <- function(df, doc_names){
  invisible(capture.output(df2 <- as_tibble(df$theta, 
                                            .name_repair = "universal")))
  top_names =  df2 %>%
    colnames() %>%
    str_replace(c("..."), paste("T", colnames(.), sep = ""))
  colnames(df2) <- top_names
  df2 %>%
    cbind(app_nums_brand = doc_names) %>%
    invisible()
}

create_primary_train_sets<- function(tgt_name, dfs, mode = "norm",
                                     topics = 0) {
  set.seed(221000000)
  #Use higher initial partition size since this will be upsampled...
  trainIndex = createDataPartition(y = dfs[[tgt_name]], p = .70, 
                                   list = FALSE, times = 1)
  train = dfs[trainIndex, ]
  test = dfs[-trainIndex, ]
  pat_stm = NA
  fd = NA

## Need to create alternate scaling for test sets based on min/max of train
## https://hastie.su.domains/ElemStatLearn/printings/ESLII_print12_toc.pdf
## Also here: 
##https://stats.stackexchange.com/questions/174823/how-to-apply-standardization
##-normalization-to-train-and-testset-if-prediction-i
  
# V_1_4_1 Added independent topic models for training set to prevent
# data leakage into test set.  
  
# V2_1: Added output of STM models.  This will be used to explain topics
# selected in downstream models. 

  
  if (mode == "stm") {
    #Add patent use code text to models for "stm" mode.  
    #Select only NDA pharmaceutical products (not OTC).
    #Add use code description to numerical text in Pats.
    #Perform StM analysis on training model.
    #Fit model to Test set.  
    
    patent_use = pats %>%
    filter(app_nums %in% train$app_nums_brand) %>%
    select(app_nums, Use) %>%
    na.omit() %>%
    distinct() %>%
    left_join(use_codes, by=c("Use" = "Code")) %>%
    group_by(app_nums) %>%
    summarize(use_text = str_c(Definition, collapse = " "), .groups = "drop_last") %>%
    ungroup() %>%
    distinct()
  
    pat_use_crp = patent_use %>%
      corpus(use_codes, docid_field = "app_nums", text_field = "use_text")
    
    train_dfm <- pat_use_crp %>%
      tokens(remove_punct = TRUE, remove_numbers = TRUE, remove_symbols = TRUE) %>%
      tokens_remove(pattern =c (stopwords(), med_stop)) %>%
      dfm()  
    
    pat_stm = train_dfm %>%
      stm(K = topics, verbose = FALSE)
    train_topic = add_top_names(pat_stm, train_dfm@Dimnames$docs)%>%
        mutate(across(where(is.numeric), replace_na, 0))

    patent_use = pats %>%
    filter(app_nums %in% test$app_nums_brand) %>%
    select(app_nums, Use) %>%
    na.omit() %>%
    distinct() %>%
    left_join(use_codes, by=c("Use" = "Code")) %>%
    group_by(app_nums) %>%
    summarize(use_text = str_c(Definition, collapse = " "), .groups = "drop_last") %>%
    ungroup() %>%
    distinct()
  
    test_dfm <- pat_use_crp %>%
      tokens(remove_punct = TRUE, remove_numbers = TRUE, remove_symbols = TRUE) %>%
      tokens_remove(pattern =c(stopwords(), med_stop)) %>%
      dfm()  
   
    out <- alignCorpus(new = convert(test_dfm, "stm"), 
                       old.vocab = pat_stm$vocab, verbose = FALSE)
  
    fd<- fitNewDocuments(model = pat_stm, documents = out$documents)
    test_topic = add_top_names(fd, test_dfm@Dimnames$docs)

    train <- left_join(train, train_topic, by = c("app_nums_brand")) %>%
        mutate(across(where(is.numeric), replace_na, 0))
    test <- left_join(test, test_topic, by = c("app_nums_brand")) %>%
        mutate(across(where(is.numeric), replace_na, 0))
  }
  min_train = sapply(select(train, where(is.numeric)), min) %>%
    list() %>%
    flatten() %>%
    as_tibble(.rows = length(train[[1]]))

  max_train = sapply(select(train, where(is.numeric)), max) %>%
    list() %>%
    flatten() %>%
    as_tibble(.rows = length(train[[1]]))

  range_train = max_train - min_train

  scale_train = ((train[colnames(min_train)] - min_train)/range_train) %>%
    cbind(select(train, !where(is.numeric)))

  min_train = slice_head(min_train, n = length(test[[1]]))
  range_train = slice_head(range_train, n = length(test[[1]]))

  scale_test <- ((test[colnames(min_train)] - min_train)/range_train) %>%
    cbind(select(test, !where(is.numeric)))
  
  return(list(scale_train, scale_test, pat_stm, fd))
}

create_upsample_train_sets <- function(train, test, tgt_name) {
  # Using upSampled training data due to large discrepancy of with / without
  # competitors.
  # Code originally deployed for PDAT 625, Module 5.
  train = upSample(x = train, 
                   y = as.factor(train[[tgt_name]]), 
                   list = FALSE, yname = "fct_has") %>%
          mutate(fct_has = NULL)

  train = mutate(train, 
                 app_nums_brand = NULL) %>%
          filter_zero_var()
  
  if(length(train) <= 1) {   
    return(list(NA, NA, NA, NA, NA, NA, NA, NA))
    }
  
  test = mutate(test, 
                app_nums_brand = NULL) %>%
         select(colnames(train))
  
  train_tgt = train[tgt_name]
  test_tgt = test[tgt_name]

    if(length(test) <= 1) {   
  return(list(NA, NA, NA, NA, NA, NA, NA, NA))}
  
  # XGB requires matrices and integers.
  # convert to character first; 
  # converting directly from factor to integer creates level(1:2)
  xgb_train_tgt = as.integer(as.character(train[[tgt_name]]))
  xgb_test_tgt = as.integer(as.character(test[[tgt_name]]))
  xgb_train = train %>%
    select(!tgt_name) 

# Check for 0 length sets before matrix conversion.  Otherwise error is called.
# 0 length sets may be observed in low variance data or small data sets.  
    if(length(xgb_train) <= 1) {   
      return(list(NA, NA, NA, NA, NA, NA, NA, NA))} 
  
  xgb_train <- xgb_train %>%
    as.matrix()
  
  xgb_test = test %>%
    select(!tgt_name) 

  if(length(xgb_test) <= 1) {   
    return(list(NA, NA, NA, NA, NA, NA, NA, NA))} 
  
  xgb_test <- xgb_test %>%  as.matrix()
  
  return(list(train, test, train_tgt, test_tgt,  
              xgb_train, xgb_test, xgb_train_tgt, xgb_test_tgt))
}
```

```{r global_analysis_fun, include = FALSE, }
do_confuse <- function(pred, tgt, pos_val = '1', levs){
  if(typeof(tgt) == "integer"){
    pred <- factor(pred)
    tgt <- factor(tgt)
    levels(pred) <- levs
    levels(tgt) <- levs
    return(confusionMatrix(pred, tgt, pos_val))
  }
  else{
    return(confusionMatrix(as.factor(pred), as.factor(tgt[[1]]), pos_val))
  }
}

get_confused <- function(mod_name, tgt, rte, train_pred, train_tgt,
                         test_pred, test_tgt, mdl, topics) {
  l1 <- vector("list", length = 8)
  l2 <- list(l1)

  l2[[1]] <- mod_name
  l2[[2]] <- tgt
  l2[[3]] <- rte
  l2[[4]] <- do_confuse(train_pred, train_tgt, '1', levels(factor(train_tgt)))
  l2[[5]] <- do_confuse(test_pred, test_tgt, '1', levels(factor(train_tgt)))
  l2[[6]] <- mdl
  #Rpart has different structure than SVM and xgboost
  if(typeof(train_tgt) == "integer") {
    l2[[7]] <- length(train_tgt)
    l2[[8]] <- length(test_tgt)
    l2[[9]] <- topics
  }
  else{
    l2[[7]] <- length(train_tgt[[1]])
    l2[[8]] <- length(test_tgt[[1]])
    l2[[9]] <- topics
  }
  names(l2) <- c("mod_name", "ct_period", "admin_route", 
                 "train_cm", "test_cm", "pred_model", "train_len", 
                 "test_len", "topics")
  return(l2)
}

print_cms <- function(cms){
  print(cms[[1]][[1]])
  print(cms[[1]][[2]])
  print(cms[[1]][[3]])
  print(cms[[1]][[4]])
}
```

```{r rpart_main, include = FALSE, }
rpart_main <- function(train, test, train_tgt, test_tgt, tgt_name, rte_name, 
                       topics){
  do_rpart_model <- function(df, form_col, tgt_col ) {
    r_control <- c(minisplit = 3, cp = 0.0001, maxdepth = 5, xval = 5)
    mod_formula = paste(backtick(form_col),  collapse = " + ")
    mod_formula = as.formula(paste(tgt_col, "~", mod_formula))
    rpart(mod_formula, data = df, control = r_control, model = TRUE)
  }
  
  prune_rpart_model <- function(rp_mod) {
    bestcp <- rp_mod$cptable[which.min(rp_mod$cptable[,"xerror"]), "CP"]
    prune(rp_mod, cp = bestcp)
  }
  
  do_prediction <- function(mdl, df) {
    predict(mdl, df, type = "class")
  }
  
  formula_cols = colnames(train[colnames(train) != tgt_name])
  
  rpart_model <- do_rpart_model(train, formula_cols, tgt_name)
  rpart_prune <- prune_rpart_model(rpart_model)
  rpart_train_pred <- do_prediction(rpart_prune, train)
  rpart_test_pred <- do_prediction(rpart_prune, test)
  return(get_confused("rpart", tgt_name, rte_name, rpart_train_pred, train_tgt, 
                       rpart_test_pred, test_tgt, rpart_prune, topics))
}
```

```{r xgboost, include = FALSE}
xgb_main <- function(train, test, train_tgt, test_tgt, tgt_name, rte_name,
                     topics, model_out = FALSE){
  do_xgb_model <- function(df, tgt){
    xgboost(data = df,
     label = tgt,
     max_depth = 6,
     subsample = 0.5,
     colsample_bytree = 0.5,
     eta = 0.33,
     #alpha = 0.0002,
     #lambda = 0.0003,
     gamma = 0.001,
     nrounds = 5000,
     nthread = 4,
     early_stopping_rounds = 4,
     verbose = 0,
     objective = "binary:hinge", 
     )
  }
  
  xgb_model <- do_xgb_model(train, train_tgt)
  xgb_train_pred <- predict(xgb_model, train)
  xgb_test_pred <- predict(xgb_model, test)
  if (model_out == TRUE) {
    return(xgb_model)
  }
  else{
    return(get_confused("xgboost", tgt_name, rte_name, 
                        xgb_train_pred, train_tgt, 
                        xgb_test_pred, test_tgt, xgb_model, topics))
  }
}
```
```{r svm_model, include = FALSE}
svm_main <- function(train, test, train_tgt, test_tgt, tgt_name, rte_name, 
                     topics){
  do_svm_model <- function(df, tgt)
    svm(x = df, y = tgt, type = 'C', cross = 5, kernel = "radial") 
  svm_model <- do_svm_model(train, train_tgt)
  svm_train_pred <- predict(svm_model, train)
  svm_test_pred <- predict(svm_model, test)
  return(get_confused("svm_model", tgt_name, rte_name, 
                      svm_train_pred, train_tgt,
                      svm_test_pred, test_tgt, svm_model, topics))
}
```

```{r sort_wide, include = FALSE}

filter_yr_route <- function(df, route, date_col, start_yr, end_yr) {
    df_wk <- df %>%
    filter(between(year(app_date), start_yr, end_yr), admin_route %in% route) %>%
    mutate(across(!c(app_nums_brand, admin_route, sponsor), as.numeric),    
           across(everything(), replace_na, 0))
    return(filter_zero_var(df_wk))
}

analyze <- function(df, 
                    filt_admin_cols = list("ORAL", "INJECTION", "INTRAVENOUS", 
                                           "TOPICAL" ),
                    filt_single_cols = list("ORAL"), ...) {
  
  filt_expiry_cols = colnames(select(df, starts_with("has_")))
  ctr = 1
  cms <- vector("list", length = 6)
  cms2 <- vector("list", length = 3)

# Using "list" parses list of names as a single entity.
# Some versions of this may look at all itemslisted in the admin cols.  
  for(rte_name in c(list(filt_admin_cols), filt_single_cols)) {
    for(tgt_name in filt_expiry_cols) {
      pat_yr <- if_else("mkt_no_pat" %in% tgt_name, "app_date",  
                        if_else("first" %in% tgt_name, 
                                "first_pat_expiry", "last_pat_expiry"))
      
      brand_as_ref <- filter_yr_route(df, rte_name, pat_yr, 1990, 2010)
      
      #Need to list excluded columns to use in negative selection.
      exclude_tgt <- select(brand_as_ref, !contains(tgt_name)) %>% 
        select(contains("has_")) %>% 
        colnames() 
      
      if(tgt_name %in% colnames(brand_as_ref)){  
        cl_df_w_tgt <- brand_as_ref %>%
          select(!c(admin_route, gen_ct, starts_with("ct_"), 
                    exclude_tgt, first_pat_expiry:app_date)) %>%
          filter_zero_var() %>%
          distinct() %>%
          mutate(across(tgt_name, as_factor)) %>%
          as_tibble() 
        
        cl_tgt <- cl_df_w_tgt %>%
          select(contains(c(tgt_name, "app_nums_brand")))
        if (length(rlang::list2(...)) >=1)
          prime_train <- create_primary_train_sets(tgt_name, cl_df_w_tgt, 
                                                   rlang::list2(...)$mode, 
                                                   rlang::list2(...)$topics)
        else{
          prime_train <- create_primary_train_sets(tgt_name, cl_df_w_tgt)
        }

        t_sets <- create_upsample_train_sets(prime_train[[1]], prime_train[[2]], 
                                             tgt_name)
        if(length(t_sets[[1]]) <= 1 | length(t_sets[[2]]) <= 1) next
        train_df <- t_sets[[1]]
        test_df <- t_sets[[2]]
        train_tgt <- t_sets[[3]]
        test_tgt <- t_sets[[4]]
        no_y_train <- t_sets[[5]]
        no_y_test <- t_sets[[6]]
        mtx_train_tgt <- t_sets[[7]]
        mtx_test_tgt <- t_sets[[8]]
        train_topics <- prime_train[[3]]
  
        cms2[[1]][[ctr]] <- rpart_main(train_df, test_df, train_tgt,
                                   test_tgt, tgt_name, rte_name, train_topics)
        cms2[[2]][[ctr]] <- xgb_main(no_y_train, no_y_test,
                                     mtx_train_tgt, mtx_test_tgt,
                                     tgt_name, rte_name, train_topics)
        cms2[[3]][[ctr]] <- svm_main(no_y_train, no_y_test,
                               mtx_train_tgt, mtx_test_tgt,
                               tgt_name, rte_name, train_topics)
        ctr = ctr + 1
      }
    }
  }

  cms_tmp <- cms2
  names(cms_tmp)<-c("rpart", "xgboost", "svm")
  
  return(flatten(cms_tmp))
}

get_stats <- function(flt){
  mod_names <- vector("list", length(flt))
  ct_period <- vector("list", length(flt))
  rte_names <- vector("list", length(flt))
  train_cm <- vector("list", length(flt))
  test_cm <- vector("list", length(flt))
  pred_model <- vector("list", length(flt))
  len_train <- vector("list", length(flt))
  len_test <- vector("list", length(flt))
  topics <- vector("list", length(flt))
  
  for(i in seq(1, length(flt), 1)){
    mod_names[[i]] <- flt[[i]]$mod_name
    ct_period[[i]] <- flt[[i]]$ct_period
    rte_names[[i]] <- flt[[i]]$admin_route
    train_cm[[i]] <- flt[[i]]$train_cm
    test_cm[[i]] <- flt[[i]]$test_cm
    pred_model[[i]] <- flt[[i]]$pred_model
    len_train[[i]] <- flt[[i]]$train_len
    len_test[[i]] <- flt[[i]]$test_len
    topics[[i]] <- flt[[i]]$topics
  }
  
  model_stats <- tibble(mod_names = mod_names,
                        ct_period =  ct_period,
                        rte_names = rte_names,
                        len_train = len_train,
                        len_test = len_test,
                        train_cm = train_cm,
                        test_cm = test_cm,
                        pred_model = pred_model,
                        topics = topics)
  
  get_short_cm <- function(x, mode = "test") {
    if (mode == "test")
    return(c("Accuracy_test" =  x[["overall"]][["Accuracy"]], 
             "NIR_test" = x[["overall"]][["AccuracyNull"]],
             "Pval_test" = x[["overall"]][["AccuracyPValue"]],
             "Prevalence_test" = x[["byClass"]][["Prevalence"]]
             )
           )
    else
    return(c("Accuracy_train" =  x[["overall"]][["Accuracy"]], 
             "NIR_train" = x[["overall"]][["AccuracyNull"]],
             "Pval_train" = x[["overall"]][["AccuracyPValue"]],
             "Prevalence_train" = x[["byClass"]][["Prevalence"]])
           )
  }
  
  model_stats2 <- model_stats %>%
    mutate(across(train_cm), 
           as_tibble(t(sapply(model_stats$train_cm, get_short_cm, "train"))),
           across(test_cm), 
           as_tibble(t(sapply(model_stats$test_cm, get_short_cm, "test"))),
           across(is.numeric, round, 3),
           rte_names = sapply(model_stats$rte_names, str_c, collapse = " "),
           mod_names = sapply(model_stats$mod_names, str_c, collapse = " "),
           ct_period = sapply(model_stats$ct_period, str_c, collapse = " "),
           len_train = as.numeric(sapply(model_stats$len_train, 
                                         str_c, collapse = " ")),
           train_cm = NULL,
           test_cm = NULL,
           len_test = as.numeric(len_test),
           len_train = as.numeric(len_train))
}
```
```{r visualize_model_perf, include = FALSE, }
show_trial_summary <- function(model_stats2){

  plt_list <- vector("list", length = 6)
  
  plt_list[[1]] =  model_stats2 %>%
      filter(len_train > 5) %>%
      ggplot(aes(x = NIR_test, y = Accuracy_test)) + 
        geom_point(aes(color = as.factor(rte_names), 
                       size = len_test),
                   alpha = 0.6) +
        geom_abline(intercept = 0, slope = 1) +
        labs(title = paste("Feature Importance, ",
                           model_stats2[[2]],  model_stats2[[3]],
                           sep = "; "))
      
  plt_list[[2]] =   model_stats2 %>%
      filter(len_train > 5) %>%
      ggplot(aes(x = NIR_test, y = Accuracy_test)) + 
        geom_point(aes(color = as.factor(mod_names), size = len_test), 
                   alpha = 0.6) +
        geom_abline(intercept = 0, slope = 1) +
        labs(title = paste("Feature Importance, ",
                           model_stats2[[2]],  model_stats2[[3]],
                           sep = "; "))
    
  plt_list[[3]] =  model_stats2 %>%
      filter(len_train > 5) %>%
      ggplot(aes(x = Pval_test, y = Accuracy_test)) + 
        geom_point(aes(color = as.factor(mod_names)),
                   alpha = 0.6) +
        geom_vline(xintercept = 0.25) +
        labs(title = paste("Feature Importance, ",
                           model_stats2[[2]],  model_stats2[[3]],
                           sep = "; "))
    
  plt_list[[4]] = model_stats2 %>%
      filter(len_train > 5) %>%
      ggplot(aes(x = Pval_test, y = NIR_test)) + 
        geom_point(aes(color = as.factor(mod_names), size = len_test),
                   alpha = 0.6) +
        geom_vline(xintercept = 0.25) + 
        facet_wrap(facets = vars(as.factor(ct_period))) +
        labs(title = paste("Feature Importance, ",
                           model_stats2[[2]],  model_stats2[[3]],
                           sep = "; "))

  plt_list[[5]] =   model_stats2 %>%
      filter(len_train > 5) %>%
      ggplot(aes(x = Pval_test, y = Accuracy_test)) + 
        geom_point(aes(color = as.factor(mod_names), size = len_test),
                   alpha = 0.6) +
        geom_vline(xintercept = 0.25) + 
        facet_wrap(facets = vars(as.factor(ct_period))) +
        labs(title = paste("Feature Importance, ",
                           model_stats2[[2]],  model_stats2[[3]],
                           sep = "; "))

  plt_list[[6]] = model_stats2 %>%
      filter(len_train > 5) %>%
      ggplot(aes(x = Pval_test, y = NIR_test)) + 
        geom_point(aes(color = as.factor(ct_period)),
                   alpha = 0.6) +
        geom_vline(xintercept = 0.25) + 
        facet_wrap(facets = vars(as.factor(rte_names))) +
        labs(title = paste("Feature Importance, ",
                           model_stats2[[2]],  model_stats2[[3]],
                           sep = "; "))
  
  return(plt_list)
  }

show_model_summary <- function(model_stats2, df){
    plt_list <- vector("list", 2*length(model_stats2[[1]]))
  for (i in seq(1, length(model_stats2[[1]]))){
    if ((model_stats2[i, "mod_names"] == "rpart") &
      (model_stats2[i, "Pval_test"] <= 1)) {
      (rpart.plot(model_stats2[[6]][[i]])) %>%
        print()
      if(!is.na(model_stats2$topics[[i]])){
        plot(model_stats2$topics[[i]], n=5)%>%
        print
      }
    }
      
  }
  
  for (i in seq(1, length(model_stats2[[1]]))){
    if ((model_stats2[i, "mod_names"] == "xgboost") &
       (model_stats2[i, "Pval_test"] <= 1)) {
      bst <- xgb.Booster.complete(model_stats2[[6]][[i]])   
      xgb.importance(model = bst) %>% 
      xgb.ggplot.importance(top_n = 24) %>%
        print()
      
      xgb.ggplot.deepness(model = bst, which = "2x1") %>%
        print()
        if(!is.na(model_stats2$topics[[i]])){
          plot(model_stats2$topics[[i]], n=5)%>%
          print
        }
      }  
  }
}

```
```{r clean_input_data, include = FALSE}
#Need to eliminate cases with no patents.
#analysis specifically looks at entry before / after patent expiry.  
brands_w_pats_stats <- brands_w_pats_stats %>%
  select(!c(has_on_first, has_on_last, has_after_mkt_no_pat)) %>%
  filter(between(year(app_date),1990, 2010), pat_ct > 0 ) %>%
  mutate(has_before_first = replace_na(has_before_first, FALSE),
         has_before_last = replace_na(has_before_last, FALSE),
         has_after_last = replace_na(has_after_last, FALSE),
         across(contains("ct_"), replace_na, 0))


```
```{r basic_model_trials, include = FALSE, cache = TRUE}
#added values fill = 0 11/11/2022
prepare_trial <- function(df1){
  mutate(df1, dose_val = 1) %>%
  distinct() %>%
  pivot_wider(names_from = dosage_form,
              values_from = dose_val,
              names_repair = "universal",
              values_fill = 0) %>%
  mutate(across(where(is_integer), replace_na, 0),
         across(where(is_logical), replace_na, FALSE)) %>%
  return()
}

filt_admin_cols <- list("ORAL", "INJECTION", "INTRAVENOUS", "TOPICAL" )
filt_single_cols <- list("ORAL")
filt_expiry_cols <- colnames(select(brands_w_pats_stats, starts_with("has_")))

master_model_A <- tibble()
master_stats_A <- tibble()

trial <- brands_w_pats_stats %>%
  prepare_trial()
flt_model_stats <- analyze(trial, filt_admin_cols)
model_stats <- get_stats(flt_model_stats)
master_stats_A <- rbind(master_stats_A, select(model_stats, !c(pred_model, topics)))
master_model_A <- rbind(master_model_A, model_stats)

trial <- brands_w_pats_stats %>%
  inner_join(ingredients_wide, by = c("app_nums_brand" = "app_nums")) %>%  
  prepare_trial()
flt_model_stats <- analyze(trial, filt_admin_cols)
model_stats <- get_stats(flt_model_stats)
master_stats_A <- rbind(master_stats_A, select(model_stats, !c(pred_model, topics)))
master_model_A <- rbind(master_model_A, model_stats)

trial <- brands_w_pats_stats %>%
  inner_join(pkg_wide, by = c("app_nums_brand" = "app_num")) %>% 
  prepare_trial()
flt_model_stats <- analyze(trial, filt_admin_cols)
model_stats <- get_stats(flt_model_stats)
master_stats_A <- rbind(master_stats_A, select(model_stats, !c(pred_model, topics)))
master_model_A <- rbind(master_model_A, model_stats)

```

```{r topic_model_trials, include = FALSE, cache = TRUE}

master_model_B  <- tibble()
master_stats_B <- tibble()

trial <- brands_w_pats_stats %>%
  prepare_trial()
flt_model_stats <- analyze(trial, filt_admin_cols, , mode = "stm", topics = 10)
model_stats <- get_stats(flt_model_stats)
master_stats_B <- rbind(master_stats_B, select(model_stats, !c(pred_model, topics)))
master_model_B <- rbind(master_model_B, model_stats)

trial <- brands_w_pats_stats %>%
  prepare_trial()
flt_model_stats <- analyze(trial, filt_admin_cols, mode = "stm", topics = 60)
model_stats <- get_stats(flt_model_stats)
master_stats_B <- rbind(master_stats_B, select(model_stats, !c(pred_model, topics)))
master_model_B <- rbind(master_model_B, model_stats)

trial <- brands_w_pats_stats %>%
  prepare_trial()
flt_model_stats <- analyze(trial, filt_admin_cols, mode = "stm", topics = 120)
model_stats <- get_stats(flt_model_stats)
master_stats_B <- rbind(master_stats_B, select(model_stats, !c(pred_model, topics)))
master_model_B <- rbind(master_model_B, model_stats)
```
```{r topic60_trials, include = FALSE, cache = TRUE}
master_model_C  <- tibble()
master_stats_C <- tibble()

trial <- brands_w_pats_stats %>%
  inner_join(pkg_wide, by = c("app_nums_brand" = "app_num")) %>% 
  prepare_trial()
flt_model_stats <- analyze(trial, filt_admin_cols, mode = "stm", topics = 60)
model_stats <- get_stats(flt_model_stats)

master_stats_C <- rbind(master_stats_C, select(model_stats, !c(pred_model, topics)))
master_model_C <- rbind(master_model_C, model_stats)

trial <- brands_w_pats_stats %>%
  inner_join(pkg_wide, by = c("app_nums_brand" = "app_num")) %>% 
  inner_join(ingredients_wide, by = c("app_nums_brand" = "app_nums")) %>% 
  prepare_trial()
flt_model_stats <- analyze(trial, filt_admin_cols, mode = "stm", topics = 60)
model_stats <- get_stats(flt_model_stats)
master_stats_C <- rbind(master_stats_C, select(model_stats, !c(pred_model, topics)))
master_model_C <- rbind(master_model_C, model_stats)

trial <- brands_w_pats_stats %>%
  inner_join(ingredients_wide, by = c("app_nums_brand" = "app_nums")) %>% 
  prepare_trial()
flt_model_stats <- analyze(trial, filt_admin_cols, mode = "stm", topics = 60)
model_stats <- get_stats(flt_model_stats)
master_stats_C <- rbind(master_stats_C, select(model_stats, !c(pred_model, topics)))
master_model_C <- rbind(master_model_C, model_stats)

trial <- brands_w_pats_stats %>%
  inner_join(ingredients_wide, by = c("app_nums_brand" = "app_nums")) %>%
  inner_join(pkg_wide, by = c("app_nums_brand" = "app_num")) %>% 
  prepare_trial()
flt_model_stats <- analyze(trial, filt_admin_cols)
model_stats <- get_stats(flt_model_stats)
master_stats_C <- rbind(master_stats_C, select(model_stats, !c(pred_model, topics)))
master_model_C <- rbind(master_model_C, model_stats)
```
```{r low_topics, include = FALSE, cache = TRUE}
master_stats_d <- tibble()
master_model_d <- tibble()

trial <- brands_w_pats_stats %>%
  inner_join(pkg_wide, by = c("app_nums_brand" = "app_num")) %>% 
  prepare_trial()
flt_model_stats <- analyze(trial, filt_admin_cols, mode = "stm", topics = 10)
model_stats <- get_stats(flt_model_stats)
master_stats_d <- rbind(master_stats_d, select(model_stats, !c(pred_model, topics)))
master_model_d <- rbind(master_model_d, model_stats)

trial <- brands_w_pats_stats %>%
  inner_join(pkg_wide, by = c("app_nums_brand" = "app_num")) %>% 
  inner_join(ingredients_wide, by = c("app_nums_brand" = "app_nums")) %>% 
  prepare_trial()
flt_model_stats <- analyze(trial, filt_admin_cols , mode = "stm", topics = 10)
model_stats <- get_stats(flt_model_stats)
master_stats_d <- rbind(master_stats_d, select(model_stats, !c(pred_model, topics)))
master_model_d <- rbind(master_model_d, model_stats)

trial <- brands_w_pats_stats %>%
  inner_join(ingredients_wide, by = c("app_nums_brand" = "app_nums")) %>% 
  prepare_trial()
flt_model_stats <- analyze(trial, filt_admin_cols, mode = "stm", topics = 10)
model_stats <- get_stats(flt_model_stats)
master_stats_d <- rbind(master_stats_d, select(model_stats, !c(pred_model, topics)))
master_model_d <- rbind(master_model_d, model_stats)
```
